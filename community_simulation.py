"""
Oasis Agent ç¤¾åŒº - åˆå¹¶ç‰ˆ (Local Only)

åˆå¹¶è‡ªï¼š
- community_simulation.py
- community_sim_0115_0204.py
- community_sim_0131_0204.py
- my_oasis_community.py

åªä¿ç•™ä¸€ä¸ªç»Ÿä¸€å…¥å£ï¼Œæ”¯æŒï¼š
1) æœ¬åœ° vLLM + Qwen3-4B-Instruct-2507
2) Twitter / Reddit å¹³å°é€‰æ‹©
3) è‡ªå®šä¹‰ Agent æ•°é‡ã€è½®æ¬¡ã€åŠ¨ä½œä¸Žæ•°æ®åº“è·¯å¾„
4) æ‰“å° vLLM å¯åŠ¨å‘½ä»¤
"""

import argparse
import asyncio
import os
from typing import Dict, List, Optional


DEFAULT_MODEL_RELATIVE = os.path.join(
    os.path.dirname(__file__), "models", "Qwen3-4B-Instruct-2507"
)
DEFAULT_MODEL_FALLBACK = "/mnt/shared-storage-user/qianchen1/models/Qwen3-4B-Instruct-2507"


AGENT_CONFIGS: List[Dict[str, str]] = [
    {"user_name": "tech_explorer", "name": "Alice",
     "description": "ç§‘æŠ€çˆ±å¥½è€…ï¼Œå–œæ¬¢æŽ¢ç´¢æ–°æŠ€æœ¯", "persona": "å¯¹AIå’Œæ–°æŠ€æœ¯å……æ»¡çƒ­æƒ…"},
    {"user_name": "data_scientist", "name": "Bob",
     "description": "æ•°æ®ç§‘å­¦å®¶ï¼Œä¸“æ³¨äºŽæœºå™¨å­¦ä¹ ", "persona": "ç”¨æ•°æ®è¯´è¯"},
    {"user_name": "ai_researcher", "name": "Charlie",
     "description": "AIç ”ç©¶å‘˜", "persona": "æ€è€ƒAIçš„æœªæ¥å’Œä¼¦ç†"},
    {"user_name": "startup_founder", "name": "Diana",
     "description": "åˆ›ä¸šè€…", "persona": "è¿½æ±‚åˆ›æ–°å’Œçªç ´"},
    {"user_name": "software_architect", "name": "Eve",
     "description": "è½¯ä»¶æž¶æž„å¸ˆ", "persona": "æ³¨é‡ç³»ç»Ÿè®¾è®¡"},
    {"user_name": "product_manager", "name": "Frank",
     "description": "äº§å“ç»ç†", "persona": "ä»¥ç”¨æˆ·éœ€æ±‚ä¸ºå¯¼å‘"},
    {"user_name": "devops_engineer", "name": "Grace",
     "description": "DevOpså·¥ç¨‹å¸ˆ", "persona": "è‡ªåŠ¨åŒ–çš„å¿ å®žä¿¡å¾’"},
    {"user_name": "ux_designer", "name": "Henry",
     "description": "UXè®¾è®¡å¸ˆ", "persona": "ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒ"},
    {"user_name": "security_expert", "name": "Ivy",
     "description": "å®‰å…¨ä¸“å®¶", "persona": "æ³¨é‡å®‰å…¨ç»†èŠ‚"},
    {"user_name": "tech_writer", "name": "Jack",
     "description": "æŠ€æœ¯ä½œå®¶", "persona": "ç®€åŒ–å¤æ‚æŠ€æœ¯"},
]


SIMPLE_ROLES = [
    "ç¤¾åŒºç®¡ç†å‘˜ï¼Œå–œæ¬¢å‘å¸ƒå…¬å‘Š", "AIæŠ€æœ¯ç‹‚çƒ­è€…", "æ—¥å¸¸ç”Ÿæ´»åˆ†äº«è€…",
    "æ½œæ°´å‘˜ï¼Œå¶å°”ç‚¹èµž", "æ¿€è¿›çš„è¯„è®ºå®¶", "ä¹äºŽåŠ©äººçš„ä¸“å®¶",
    "å¹½é»˜çš„æ®µå­æ‰‹", "æ–°é—»æ¬è¿å·¥", "åˆšæ³¨å†Œçš„æ–°äºº", "å¥½å¥‡å®å®",
]


class DummyTokenCounter:
    def count_tokens_from_messages(self, messages):
        return 0

    def count_tokens(self, text):
        return 0


def resolve_model_path(explicit_path: Optional[str]) -> str:
    candidates: List[str] = []
    if explicit_path:
        candidates.append(explicit_path)
    env_path = os.environ.get("OASIS_MODEL_PATH", "").strip()
    if env_path:
        candidates.append(env_path)
    candidates.append(DEFAULT_MODEL_RELATIVE)
    candidates.append(DEFAULT_MODEL_FALLBACK)
    for path in candidates:
        if path and os.path.exists(path):
            return path
    return candidates[0] if candidates else ""


def build_agent_configs(num_agents: int, use_simple_roles: bool) -> List[Dict[str, str]]:
    configs: List[Dict[str, str]] = []
    if use_simple_roles:
        for i in range(num_agents):
            role_desc = SIMPLE_ROLES[i] if i < len(SIMPLE_ROLES) else "æ™®é€šç¤¾åŒºæˆå‘˜"
            configs.append({
                "user_name": f"user_{i}",
                "name": f"User_{i}",
                "description": f"æˆ‘æ˜¯User_{i}ï¼Œæˆ‘æ˜¯ä¸€ä¸ª{role_desc}ã€‚",
                "persona": role_desc,
            })
    else:
        configs = [dict(c) for c in AGENT_CONFIGS]
        if num_agents > len(configs):
            for i in range(len(configs), num_agents):
                configs.append({
                    "user_name": f"user_{i}",
                    "name": f"User_{i}",
                    "description": "ç¤¾åŒºæˆå‘˜",
                    "persona": "æ™®é€šç”¨æˆ·",
                })
        else:
            configs = configs[:num_agents]
    return configs


def print_vllm_command(model_path: str, api_url: str, max_model_len: int, gpu_mem_util: float) -> None:
    host, port = "0.0.0.0", "8000"
    if api_url.startswith("http://") or api_url.startswith("https://"):
        try:
            host_port = api_url.split("://", 1)[1].split("/", 1)[0]
            if ":" in host_port:
                host, port = host_port.split(":", 1)
        except Exception:
            pass
    print("\nðŸ“¦ æŽ¨è vLLM å¯åŠ¨å‘½ä»¤ï¼š")
    print("python -m vllm.entrypoints.openai.api_server \\")
    print(f"  --model {model_path} \\")
    print(f"  --host {host} \\")
    print(f"  --port {port} \\")
    print("  --trust-remote-code \\")
    print("  --enable-auto-tool-choice \\")
    print("  --tool-call-parser hermes \\")
    print(f"  --max-model-len {max_model_len} \\")
    print(f"  --gpu-memory-utilization {gpu_mem_util}")


async def create_qwen_model(model_type: str, api_url: str, temperature: float):
    from camel.models import ModelFactory
    from camel.types import ModelPlatformType

    model = ModelFactory.create(
        model_platform=ModelPlatformType.VLLM,
        model_type=model_type,
        url=api_url,
        api_key="EMPTY",
        model_config_dict={"temperature": temperature},
    )
    model._token_counter = DummyTokenCounter()
    return model


def apply_offline_patches(oasis_module):
    import oasis.social_platform.platform
    import oasis.social_platform.recsys

    def patched_random_rec(*args, **kwargs):
        try:
            post_table = args[1]
            rec_matrix = args[4]
            max_rec_post_len = args[5]
            return oasis_module.social_platform.recsys.rec_sys_random(
                post_table, rec_matrix, max_rec_post_len
            )
        except Exception as e:
            print(f"âš ï¸ æŽ¨èç³»ç»Ÿè¡¥ä¸è¿è¡Œè­¦å‘Š: {e}, è¿”å›žç©ºåˆ—è¡¨")
            return [[] for _ in range(len(args[4]))]

    oasis_module.social_platform.platform.rec_sys_personalized_twh = patched_random_rec
    print("âœ… è¡¥ä¸ç”Ÿæ•ˆï¼šå·²ç¦ç”¨ HuggingFace æ¨¡åž‹ä¸‹è½½ (ä½¿ç”¨éšæœºæŽ¨è)")


async def main():
    print("ðŸš€ å¯åŠ¨ Oasis Agent ç¤¾åŒºï¼ˆåˆå¹¶ç‰ˆï¼‰...")

    parser = argparse.ArgumentParser()
    parser.add_argument("--model-path", default=os.environ.get("OASIS_MODEL_PATH", ""))
    parser.add_argument("--model-name", default=os.environ.get("OASIS_VLLM_MODEL_NAME", ""))
    parser.add_argument("--api-url", default=os.environ.get("OASIS_VLLM_URL", "http://localhost:8000/v1"))
    parser.add_argument("--db-path", default=os.environ.get("OASIS_DB_PATH", "./community_simulation.db"))
    parser.add_argument("--rounds", type=int, default=int(os.environ.get("OASIS_COMMUNITY_ROUNDS", "3")))
    parser.add_argument("--num-agents", type=int, default=int(os.environ.get("OASIS_NUM_AGENTS", "10")))
    parser.add_argument("--platform", choices=["twitter", "reddit"],
                        default=os.environ.get("OASIS_PLATFORM", "twitter"))
    parser.add_argument("--recsys-type", choices=["random", "twitter", "reddit"],
                        default=os.environ.get("OASIS_RECSYS_TYPE", ""))
    parser.add_argument("--use-simple-roles", action="store_true",
                        default=os.environ.get("OASIS_SIMPLE_ROLES", "") not in ("", "0", "false", "False"))
    parser.add_argument("--temperature", type=float,
                        default=float(os.environ.get("OASIS_MODEL_TEMPERATURE", "0.7")))
    parser.add_argument("--initial-post",
                        default=os.environ.get(
                            "OASIS_INITIAL_POST",
                            "ðŸŽ‰ æ¬¢è¿Žæ¥åˆ° Oasis Agent ç¤¾åŒºï¼æˆ‘ä»¬æ˜¯ 10 ä¸ªAIåŠ©æ‰‹ï¼Œåœ¨è¿™é‡Œè¿›è¡Œç¤¾äº¤äº’åŠ¨ã€‚"
                        ))
    parser.add_argument("--topics-csv",
                        default=os.environ.get("OASIS_TOPICS_CSV", "data/twitter_dataset/all_topics.csv"))
    parser.add_argument("--topics-field",
                        default=os.environ.get("OASIS_TOPICS_FIELD", ""))
    parser.add_argument("--topics-num", type=int,
                        default=int(os.environ.get("OASIS_TOPICS_NUM", "3")))
    parser.add_argument("--topics-seed", type=int,
                        default=int(os.environ.get("OASIS_TOPICS_SEED", "42")))
    parser.add_argument("--topics-mode", choices=["initial", "per-round"],
                        default=os.environ.get("OASIS_TOPICS_MODE", "initial"))
    parser.add_argument("--topics-per-round", type=int,
                        default=int(os.environ.get("OASIS_TOPICS_PER_ROUND", "3")))
    parser.add_argument("--extra-comments", action="store_true",
                        default=os.environ.get("OASIS_EXTRA_COMMENTS", "") not in ("", "0", "false", "False"))
    parser.add_argument("--show-agent-summary", action="store_true",
                        default=os.environ.get("OASIS_SHOW_AGENT_SUMMARY", "") not in ("", "0", "false", "False"))
    parser.add_argument("--print-vllm", action="store_true")
    parser.add_argument("--check-only", action="store_true")
    parser.add_argument("--max-model-len", type=int, default=8192)
    parser.add_argument("--gpu-memory-utilization", type=float, default=0.90)
    args = parser.parse_args()

    model_path = resolve_model_path(args.model_path)
    if not model_path or not os.path.exists(model_path):
        print("âŒ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡åž‹è·¯å¾„ã€‚")
        print("è¯·è®¾ç½®çŽ¯å¢ƒå˜é‡ OASIS_MODEL_PATHï¼Œæˆ–ä¼ å…¥ --model-pathã€‚")
        print("ä¾‹å¦‚: export OASIS_MODEL_PATH=/path/to/Qwen3-4B-Instruct-2507")
        return

    if args.print_vllm:
        print_vllm_command(model_path, args.api_url, args.max_model_len, args.gpu_memory_utilization)
        if args.check_only:
            return

    if args.check_only:
        print("âœ… æ£€æŸ¥å®Œæˆã€‚")
        return

    import oasis
    from camel.models import ModelManager
    from oasis import (ActionType, AgentGraph, LLMAction, ManualAction,
                       SocialAgent, UserInfo)

    apply_offline_patches(oasis)

    model_type = args.model_name.strip() if args.model_name.strip() else model_path
    print(f"ðŸ“¦ è¿žæŽ¥æ¨¡åž‹: {model_path}")
    try:
        model = await create_qwen_model(model_type, args.api_url, args.temperature)
        model_manager = ModelManager(models=[model], scheduling_strategy="round_robin")
        print("âœ… æ¨¡åž‹è¿žæŽ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡åž‹åˆå§‹åŒ–å¤±è´¥: {e}")
        print("ðŸ’¡ è¯·æ£€æŸ¥ vLLM æ˜¯å¦ä½¿ç”¨ç›¸åŒçš„è·¯å¾„å¯åŠ¨")
        return

    available_actions = [
        ActionType.LIKE_POST,
        ActionType.LIKE_COMMENT,
        ActionType.DISLIKE_POST,
        ActionType.CREATE_POST,
        ActionType.CREATE_COMMENT,
        ActionType.FOLLOW,
        ActionType.UNFOLLOW,
        ActionType.REPOST,
    ]

    recsys_type = args.recsys_type.strip()
    if not recsys_type:
        recsys_type = "reddit" if args.platform == "reddit" else "twitter"

    agent_graph = AgentGraph()
    agents = []
    configs = build_agent_configs(args.num_agents, args.use_simple_roles)

    print(f"ðŸ‘¥ åˆ›å»º {len(configs)} ä¸ª Agents...")
    for i, config in enumerate(configs):
        user_info = UserInfo(
            user_name=config["user_name"],
            name=config["name"],
            description=config["description"],
            profile={"other_info": {"user_profile": config["persona"]}} if config.get("persona") else None,
            recsys_type=recsys_type,
        )
        agent = SocialAgent(
            agent_id=i,
            user_info=user_info,
            agent_graph=agent_graph,
            model=model_manager,
            available_actions=available_actions,
        )
        agent_graph.add_agent(agent)
        agents.append(agent)
        print(f"  - Agent {i}: {agent.user_info.name}")

    print("ðŸ”— å»ºç«‹ç¤¾äº¤ç½‘ç»œ...")
    for i in range(len(configs)):
        for j in range(len(configs)):
            if i != j and j % 2 == 0:
                agent_graph.add_edge(i, j)
    print("âœ… ç¤¾äº¤ç½‘ç»œæž„å»ºå®Œæˆ")

    db_path = args.db_path
    os.makedirs(os.path.dirname(os.path.abspath(db_path)), exist_ok=True)
    if os.path.exists(db_path):
        os.remove(db_path)
    os.environ["OASIS_DB_PATH"] = os.path.abspath(db_path)

    print("ðŸŒ åˆ›å»ºæ¨¡æ‹ŸçŽ¯å¢ƒ...")
    platform_type = oasis.DefaultPlatformType.TWITTER if args.platform == "twitter" else oasis.DefaultPlatformType.REDDIT
    env = oasis.make(
        agent_graph=agent_graph,
        platform=platform_type,
        database_path=db_path,
    )

    await env.reset()
    print("âœ… çŽ¯å¢ƒå‡†å¤‡å°±ç»ª")

    print("ðŸ“ å‘å¸ƒåˆå§‹å†…å®¹...")
    initial_actions = {
        env.agent_graph.get_agent(0): [
            ManualAction(
                action_type=ActionType.CREATE_POST,
                action_args={"content": args.initial_post}
            )
        ]
    }

    topics_csv_path = os.path.join(os.path.dirname(__file__), args.topics_csv) if not os.path.isabs(args.topics_csv) else args.topics_csv
    topics_list = []
    if os.path.exists(topics_csv_path):
        try:
            import pandas as pd
            df_topics = pd.read_csv(topics_csv_path)
            topic_col = None
            if args.topics_field and args.topics_field in df_topics.columns:
                topic_col = args.topics_field
            elif "source_tweet" in df_topics.columns:
                topic_col = "source_tweet"
            elif "topic_name" in df_topics.columns:
                topic_col = "topic_name"

            if topic_col:
                df_topics = df_topics.dropna(subset=[topic_col])
                df_topics[topic_col] = df_topics[topic_col].astype(str)
                df_topics = df_topics[df_topics[topic_col].str.strip() != ""]
                if len(df_topics) > 0:
                    if args.topics_num <= 0:
                        sampled = df_topics[topic_col].tolist()
                    else:
                        sampled = df_topics.sample(
                            n=min(args.topics_num, len(df_topics)),
                            random_state=args.topics_seed
                        )[topic_col].tolist()
                    topics_list = sampled
        except Exception as e:
            print(f"âš ï¸ è¯»å–è¯é¢˜ CSV å¤±è´¥: {e}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°è¯é¢˜ CSV: {topics_csv_path}")

    # è¿½åŠ å¤šä¸ªè¯é¢˜ä½œä¸ºåˆå§‹å¸–å­
    if topics_list and args.topics_mode == "initial":
        for idx, topic in enumerate(topics_list, start=1):
            initial_actions[env.agent_graph.get_agent(0)].append(
                ManualAction(
                    action_type=ActionType.CREATE_POST,
                    action_args={"content": f"ã€è¯é¢˜ {idx}ã€‘{topic}"}
                )
            )

    await env.step(initial_actions)

    print("ðŸ¤– å¼€å§‹ Agent äº¤äº’...")
    topic_index = 0
    for round_num in range(args.rounds):
        print(f"  è½®æ¬¡ {round_num + 1}/{args.rounds}")

        if topics_list and args.topics_mode == "per-round":
            # æ¯è½®å…ˆå‘å¸ƒä¸€æ‰¹è¯é¢˜
            batch = topics_list[topic_index: topic_index + max(1, args.topics_per_round)]
            if batch:
                topic_index += len(batch)
                topic_actions = {
                    env.agent_graph.get_agent(0): [
                        ManualAction(
                            action_type=ActionType.CREATE_POST,
                            action_args={"content": f"ã€è¯é¢˜ {topic_index - len(batch) + i + 1}ã€‘{topic}"}
                        )
                        for i, topic in enumerate(batch)
                    ]
                }
                await env.step(topic_actions)

        actions = {agent: LLMAction() for _, agent in env.agent_graph.get_agents()}
        await env.step(actions)

        if args.extra_comments and round_num == 0:
            extra_actions = {
                env.agent_graph.get_agent(1): [
                    ManualAction(
                        action_type=ActionType.CREATE_COMMENT,
                        action_args={
                            "post_id": "1",
                            "content": "å¤ªæ£’äº†ï¼ä½œä¸ºæ•°æ®ç§‘å­¦å®¶ï¼Œæˆ‘å¾ˆæœŸå¾…çœ‹åˆ°è¿™ä¸ªç¤¾åŒºçš„äº’åŠ¨æ¨¡å¼ï¼ðŸ“Š"
                        }
                    )
                ],
                env.agent_graph.get_agent(2): [
                    ManualAction(
                        action_type=ActionType.CREATE_COMMENT,
                        action_args={
                            "post_id": "1",
                            "content": "AI ç ”ç©¶å‘˜è§†è§’ï¼šè¿™å°†æ˜¯ä¸€ä¸ªç ”ç©¶ç¤¾äº¤AIè¡Œä¸ºçš„å¥½æœºä¼šï¼ðŸ¤–"
                        }
                    )
                ],
            }
            await env.step(extra_actions)

    print("\nðŸ“Š ç¤¾åŒºç»Ÿè®¡:")
    print("=" * 40)
    for i in range(len(configs)):
        agent = env.agent_graph.get_agent(i)
        print(f"Agent {i}: {agent.user_info.name} (@{agent.user_info.user_name})")
        if args.show_agent_summary:
            print(f"  - æè¿°: {agent.user_info.description}")
            if agent.user_info.profile and "other_info" in agent.user_info.profile:
                persona = agent.user_info.profile["other_info"].get("user_profile", "")
                if persona:
                    print(f"  - Persona: {persona}")

    await env.close()
    print(f"\nâœ… æ¨¡æ‹Ÿå®Œæˆï¼æ•°æ®åº“: {db_path}")


if __name__ == "__main__":
    asyncio.run(main())
